{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import jieba\n",
    "# 导入所需模块\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfTransformer,TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold,StratifiedKFold,cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取训练测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7355 entries, 0 to 7354\n",
      "Data columns (total 3 columns):\n",
      "id       7355 non-null object\n",
      "text     7354 non-null object\n",
      "label    7355 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 172.5+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7356 entries, 0 to 7355\n",
      "Data columns (total 2 columns):\n",
      "id      7356 non-null object\n",
      "text    7356 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 115.0+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7355 entries, 0 to 7354\n",
      "Data columns (total 3 columns):\n",
      "id       7355 non-null object\n",
      "text     7354 non-null object\n",
      "label    7355 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 172.5+ KB\n"
     ]
    }
   ],
   "source": [
    "def read_all_data():\n",
    "    train_data = pd.read_csv(\"./input/Train_DataSet.csv\")\n",
    "    test_data = pd.read_csv(\"./input/Test_DataSet.csv\")\n",
    "    return train_data,test_data\n",
    "    \n",
    "def read_title_data():\n",
    "    train_x = pd.read_csv(\"./input/data/Train_DataSet_title_content.csv\")\n",
    "    train_data = train_x.drop([\"content\"],axis = 1)\n",
    "    train_data = train_data.rename(columns={\"title\":\"text\"})\n",
    "    #train_data.dropna(axis=0,inplace = True)\n",
    "    print(train_data.info())\n",
    "    \n",
    "    test_data = pd.read_csv(\"./input/data/Test_DataSet.csv\")\n",
    "    test_data.drop([\"content\"],axis=1,inplace = True)\n",
    "    test_data = test_data.rename(columns={\"title\":\"text\"})\n",
    "    print(test_data.info())\n",
    "    return train_data,test_data\n",
    "\n",
    "\n",
    "train_data,test_data = read_title_data()\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7a3dd79f90ee419da87190cff60f7a86</td>\n",
       "      <td>问责领导(上黄镇党委书记张涛，宣国才真能一手遮天吗？)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7640a5589bc7486ca199eeeb38af79dd</td>\n",
       "      <td>江歌事件:教会孩子，善良的同时更要懂得保护自己!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8c5bda93e4ba401f90a0faa5b28fe57f</td>\n",
       "      <td>绝味鸭脖广告\"开黄腔\"引众怒\"双11\"这么拼值吗?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1aa777fed31a4b8a9d866f05b5477557</td>\n",
       "      <td>央视曝光!如东一医药企业将槽罐车改成垃圾车，夜间偷排高浓度废水</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6c67ac55360340258e157f3710ebae6c</td>\n",
       "      <td>恶劣至极，央视都曝光了!南通如东一医药企业将槽罐车改成洒水车，夜间偷排高浓度废水丢大发了!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  7a3dd79f90ee419da87190cff60f7a86   \n",
       "1  7640a5589bc7486ca199eeeb38af79dd   \n",
       "2  8c5bda93e4ba401f90a0faa5b28fe57f   \n",
       "3  1aa777fed31a4b8a9d866f05b5477557   \n",
       "4  6c67ac55360340258e157f3710ebae6c   \n",
       "\n",
       "                                            text  label  \n",
       "0                    问责领导(上黄镇党委书记张涛，宣国才真能一手遮天吗？)      2  \n",
       "1                       江歌事件:教会孩子，善良的同时更要懂得保护自己!      1  \n",
       "2                      绝味鸭脖广告\"开黄腔\"引众怒\"双11\"这么拼值吗?      2  \n",
       "3                央视曝光!如东一医药企业将槽罐车改成垃圾车，夜间偷排高浓度废水      2  \n",
       "4  恶劣至极，央视都曝光了!南通如东一医药企业将槽罐车改成洒水车，夜间偷排高浓度废水丢大发了!      2  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jieba进行分词\n",
    "def train_word_cut(df_train):\n",
    "    return \" \".join(jieba.cut(df_train))\n",
    "\n",
    "def test_word_cut(df_test):\n",
    "    return \" \".join(jieba.cut(df_test))\n",
    "\n",
    "def get_custom_stopwords(stop_words_file):\n",
    "    with open(stop_words_file, 'r', encoding='utf-8') as f:\n",
    "        stopwords = f.read()\n",
    "    stopwords_list = stopwords.split('\\n')\n",
    "    custom_stopwords_list = [i for i in stopwords_list]\n",
    "    return custom_stopwords_list\n",
    "\n",
    "stop_words_file = \"./input/stop_word/stopwordsHIT.txt\"\n",
    "stopwords = get_custom_stopwords(stop_words_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                               九江 办好 人民满意 教育\n",
       "1    中央 第三 生态 环境保护 督察组 转办 我市 第三十 一批 信访件 办理 情况\n",
       "2                     大雨天 车 被淹 ， 保险公司 该不该 赔 ？\n",
       "3              英特尔 新 cpu 微 架构 ocean   cove 曝光\n",
       "4      公安部 侦破 一批 重大 网络 赌博 案件   德州 约局 平台 成 重灾区\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# 训练数据分词\n",
    "train_data[\"text\"] = train_data[\"text\"].astype(str)\n",
    "train_data[\"text\"] = train_data.text.apply(train_word_cut)\n",
    "# 测试数据分词\n",
    "test_data[\"text\"] = test_data[\"text\"].astype(str)\n",
    "test_data[\"text\"] = test_data.text.apply(test_word_cut)\n",
    "test_data.text.head() # 查看测试集分词前几行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7a3dd79f90ee419da87190cff60f7a86</td>\n",
       "      <td>2.0</td>\n",
       "      <td>问责 领导 ( 上 黄镇 党委书记 张涛 ， 宣国 才 真能 一手遮天 吗 ？ )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7640a5589bc7486ca199eeeb38af79dd</td>\n",
       "      <td>1.0</td>\n",
       "      <td>江歌 事件 : 教会 孩子 ， 善良 的 同时 更要 懂得 保护 自己 !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8c5bda93e4ba401f90a0faa5b28fe57f</td>\n",
       "      <td>2.0</td>\n",
       "      <td>绝味 鸭 脖 广告 \" 开 黄腔 \" 引 众怒 \" 双 11 \" 这么 拼值 吗 ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1aa777fed31a4b8a9d866f05b5477557</td>\n",
       "      <td>2.0</td>\n",
       "      <td>央视 曝光 ! 如东 一 医药企业 将 槽罐车 改成 垃圾车 ， 夜间 偷排 高浓度 废水</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6c67ac55360340258e157f3710ebae6c</td>\n",
       "      <td>2.0</td>\n",
       "      <td>恶劣 至极 ， 央视 都 曝光 了 ! 南通 如东 一 医药企业 将 槽罐车 改成 洒水车 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  label  \\\n",
       "0  7a3dd79f90ee419da87190cff60f7a86    2.0   \n",
       "1  7640a5589bc7486ca199eeeb38af79dd    1.0   \n",
       "2  8c5bda93e4ba401f90a0faa5b28fe57f    2.0   \n",
       "3  1aa777fed31a4b8a9d866f05b5477557    2.0   \n",
       "4  6c67ac55360340258e157f3710ebae6c    2.0   \n",
       "\n",
       "                                                text  \n",
       "0          问责 领导 ( 上 黄镇 党委书记 张涛 ， 宣国 才 真能 一手遮天 吗 ？ )  \n",
       "1              江歌 事件 : 教会 孩子 ， 善良 的 同时 更要 懂得 保护 自己 !  \n",
       "2         绝味 鸭 脖 广告 \" 开 黄腔 \" 引 众怒 \" 双 11 \" 这么 拼值 吗 ?  \n",
       "3      央视 曝光 ! 如东 一 医药企业 将 槽罐车 改成 垃圾车 ， 夜间 偷排 高浓度 废水  \n",
       "4  恶劣 至极 ， 央视 都 曝光 了 ! 南通 如东 一 医药企业 将 槽罐车 改成 洒水车 ...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 合并训练测试数据\n",
    "train_test = pd.concat([train_data,test_data],ignore_index=True)\n",
    "train_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer\n",
      "HashingVectorizer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<14711x1092573 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1132917 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tifldf特征提取\n",
    "train_shape = train_data.shape\n",
    "max_df = 1.0\n",
    "min_df = 1\n",
    "print(\"TfidfVectorizer\")\n",
    "tf = TfidfVectorizer(ngram_range=(1,2),\n",
    "                     analyzer='char',\n",
    "                     token_pattern=u'(?u)\\\\b[^\\\\d\\\\W]\\\\w+\\\\b',\n",
    "                    #stop_words=stopwords\n",
    "                    )\n",
    "tf_feat = tf.fit_transform(train_test['text'].values)\n",
    "print('HashingVectorizer')\n",
    "ha = HashingVectorizer(ngram_range=(1,1),\n",
    "                       analyzer='char',\n",
    "                       token_pattern=u'(?u)\\\\b[^\\\\d\\\\W]\\\\w+\\\\b',\n",
    "                       stop_words=stopwords\n",
    "                      )\n",
    "hash_feat = ha.fit_transform(train_test['text'].values)\n",
    "data = hstack((tf_feat,hash_feat)).tocsr()#hash_feat,\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lr():\n",
    "    clf_lr = LogisticRegression(C=3,class_weight=\"balanced\",penalty=\"l2\",n_jobs=-1,solver=\"sag\")\n",
    "    return clf_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7355, 1092573) (7355,) (7356, 1092573)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running 0\n",
      "(6618, 1092573) (6618,) (737, 1092573) (737,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:04,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running 1\n",
      "(6618, 1092573) (6618,) (737, 1092573) (737,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:08,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running 2\n",
      "(6619, 1092573) (6619,) (736, 1092573) (736,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:12,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running 3\n",
      "(6619, 1092573) (6619,) (736, 1092573) (736,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:15,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running 4\n",
      "(6620, 1092573) (6620,) (735, 1092573) (735,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:19,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running 5\n",
      "(6620, 1092573) (6620,) (735, 1092573) (735,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:23,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running 6\n",
      "(6620, 1092573) (6620,) (735, 1092573) (735,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:27,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running 7\n",
      "(6620, 1092573) (6620,) (735, 1092573) (735,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:30,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running 8\n",
      "(6620, 1092573) (6620,) (735, 1092573) (735,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:34,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running 9\n",
      "(6621, 1092573) (6621,) (734, 1092573) (734,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:38,  3.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7113615899930249\n"
     ]
    }
   ],
   "source": [
    "N=10\n",
    "tf_feat = data\n",
    "X = tf_feat[:train_shape[0]] # 训练集\n",
    "y = train_test['label'][:train_shape[0]] # 训练集\n",
    "test = tf_feat[train_shape[0]:] # 测试集\n",
    "print(X.shape,y.shape,test.shape)\n",
    "kf = StratifiedKFold(n_splits=N,random_state=42,shuffle=True)\n",
    "oof = np.zeros((X.shape[0],3))\n",
    "oof_test = np.zeros((test.shape[0],3))\n",
    "for j,(train_in,test_in) in tqdm(enumerate(kf.split(X,y))):\n",
    "    print('running',j)\n",
    "    X_train,X_test,y_train,y_test = X[train_in],X[test_in],y[train_in],y[test_in]\n",
    "    print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)\n",
    "    clf = make_lr().fit(X_train,y_train)\n",
    "    test_y = clf.predict_proba(X_test)\n",
    "    oof[test_in] = test_y\n",
    "    oof_test = oof_test + clf.predict_proba(test)\n",
    "xx_cv = f1_score(y,np.argmax(oof,axis=1),average='macro')\n",
    "print(xx_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "np.save(\"./pred_lr_tfidf_71.txt\",oof_test)\n",
    "result = pd.DataFrame()\n",
    "result['id'] = test_data['id']\n",
    "result['label'] = np.argmax(oof_test,axis=1)\n",
    "print('finish')\n",
    "#result[['id','label']].to_csv('./submit/base_lr_tfidf_hash_{}_830_3.csv'.format(str(np.mean(xx_cv)).split('.')[1]),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"./pred_lr_tfidf_71.txt\",oof_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.56444406, 5.14755844, 0.28799751],\n",
       "       [2.98541996, 6.27019742, 0.74438262],\n",
       "       [0.02445452, 5.5291814 , 4.44636409],\n",
       "       ...,\n",
       "       [2.04675857, 7.85848834, 0.09475309],\n",
       "       [3.95136662, 5.69428011, 0.35435327],\n",
       "       [0.86014997, 5.0085378 , 4.13131223]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pred=np.loadtxt('./pred_data.txt')\n",
    "bert_pred = np.loadtxt(\"./pred_lr_tfidf_71.txt\")\n",
    "bert_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "result = pd.DataFrame()\n",
    "result['id'] = test_data['id']\n",
    "result['label'] = np.argmax(lr_pred+bert_pred,axis=1)\n",
    "print('finish')\n",
    "result[['id','label']].to_csv('./submit/base_lrtfidfhash__bert{}_831_3.csv'.format(str(np.mean(xx_cv)).split('.')[1]),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
